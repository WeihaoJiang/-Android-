---
title: 数据结构总结
date: 2019-10-17
tags: [java，基础]
categories: java
---


## ArrayList
实际开发中很少实用数组了，最常见的就是ArrayList，所以从它说起
- 1 首先它是基于动态数组的数据结构，和数组一样在物理上是连续的，初始化时大小为10，插入新元素时会判断是否需要扩容，扩容的步长为原大小的50%，扩容时需要复制原来数组，造成开销

- 2 优势是查找效率很高（因为物理上连续）时间复杂度为O(1)，而插入或者删除指定元素时却需要移动插入位置之后的所有元素，时间复杂度为O（n),而如果在最后面进行插入，那就不需要进行位移，时间复杂度为O(1)

## LinkedList
基于这种情况，于是有了LinkedList
- 1 首先它内部使用基于链表的数据结构实现存储，所以它也具有链表的特点，每一个元素（结点）的地址不连续，通过引用找到当前结点的上一个结点和下一个结点，即插入和删除指定元素效率较高，而get和set则较为低效，时间复杂度为O(n)
   
##  ArrayList与LinkedList对比       
ArrayList 是线性表（数组）
get() 直接读取第几个下标，复杂度 O(1)
add(E) 添加元素，直接在后面添加，复杂度O（1）
add(index, E)添加元素，在第几个元素后面插入，后面的元素需要向后移动，复杂度O（n）
remove（）删除元素，后面的元素需要逐个移动，复杂度O（n）

LinkedList 是链表的操作
get() 获取第几个元素，依次遍历，复杂度O(n)
add(E) 添加到末尾，复杂度O(1)
add(index, E) 添加第几个元素后，需要先查找到第几个元素，直接指针指向操作，复杂度O(n)
remove（）删除元素，直接指针指向操作，复杂度O(1)

## HashMap

HashMap可以接受null键值和值，而且是非synchronized的，以及HashMap储存的是键值对，使用put(key, value)存储对象到HashMap中，使用get(key)从HashMap中获取对象。当我们给put()方法传递键和值时，我们先对键调用hashCode()方法得到哈希值，再结合哈希值与HashMap的长度得到储存Entry对象的位置，而当我们new一个
HashMap对象时，没有指定长度的话默认长度是16，若指定了长度则会与指定长度最接近的2的整数次幂作为该对象的初始长度，当该对象的使用率达到0.75时，会发生扩容，扩容后长度依然必须是2的整数次幂。

关于上述内容有几个问题需要思考
### 为什么HashMap的长度必须是2的整数次幂
先来看一看HashMap是如何计算出储存每一个Entry对象的位置的

![图片](https://upload-images.jianshu.io/upload_images/8031371-0886d83c99bf0275.png?imageMogr2/auto-orient/strip|imageView2/2/w/986/format/webp)
```
 /**
     * Returns index for hash code h.
     */
    static int indexFor(int h, int length) {
        return h & (length-1);
    }
```
是对hashcode和(length-1)做与运算
此时若length为16或者其他2的幂,则length - 1的值是所有二进制位全为1，那么index的结果等同于hashcode后几位的值，只要输入的hashcode本身分布均匀,hash算法的结果就是均匀的，这样一来大大的降低了哈希碰撞的几率

### 关于扩容
```
threshold = (int)(capacity * loadFactor);
```
```
void addEntry(int hash, K key, V value, int bucketIndex) {
        if ((size >= threshold) && (null != table[bucketIndex])) {
            resize(2 * table.length);//当size超过临界阈值threshold，并且即将发生哈希冲突时进行扩容
            hash = (null != key) ? hash(key) : 0;
            bucketIndex = indexFor(hash, table.length);
        }

        createEntry(hash, key, value, bucketIndex);
    }
```
在put操作时，即向容器中添加元素时，判断当前容器中元素的个数是否达到阈值（当前数组长度乘以负载因子的值）的时候，就要自动扩容了，就是新建一个长度为之前数组2倍的新的数组，然后将当前的Entry数组中的元素全部传输过去，扩容后的新数组长度为之前的2倍，所以扩容相对来说是个耗资源的操作。

#### 扩容负载因子为什么是0.75
- 1 如果负载因子为0.5甚至更低的可能的话，最后得到的临时阈值明显会很小，这样的情况就会造成分配的内存的浪费，存在多余的没用的内存空间，也不满足了哈希表均匀分布的情况。
- 2 如果负载因子达到了1的情况，也就是Entry数组存满了才发生扩容，这样会出现大量的哈希冲突的情况，出现链表过长，因此造成get查询数据的效率。
- 3 因此选择了0.5~1的折中数也就是0.75，均衡解决了上面出现的情况,是一种平衡了时间空间开销的方法

### HashMap的数据结构Java7和Java8及之后有所区别
Java7是数组+链表，当发生哈希冲突时以链表的形式存储，链表中存储格式是key-value键值对
![图片](https://upload-images.jianshu.io/upload_images/8031371-44ed77820f471459.png?imageMogr2/auto-orient/strip|imageView2/2/w/883/format/webp)
Java8是数组+链表+红黑树，当发生哈希冲突时以链表的形式存储，当链表长度大于等于8时，以红黑树的形式存储
![图片](https://upload-images.jianshu.io/upload_images/8031371-b057a459fa1cbccf.png?imageMogr2/auto-orient/strip|imageView2/2/w/1112/format/webp)
#### 为什么链表长度大于等于8时转为红黑树
这个8的设定很有讲究，是符合泊松分布概率统计学的，即经过概率分析认为超过8的概率很小，对泊松分布不太懂也没关系，在源码注释中有这么一段
```
 * factorial(k)). The first values are:
     *
     * 0:    0.60653066
     * 1:    0.30326533
     * 2:    0.07581633
     * 3:    0.01263606
     * 4:    0.00157952
     * 5:    0.00015795
     * 6:    0.00001316
     * 7:    0.00000094
     * 8:    0.00000006
     * more: less than 1 in ten million
```
官方给的概率，可以说达到8就很难了，所以实际运用中存成红黑树的情况并不多

### HashMap为什么是线程不安全的
- 1 put的时候导致的多线程数据不一致
比如有两个线程A和B，首先A希望插入一个key-value对到HashMap中，首先计算记录所要落到的 hash桶的索引坐标，然后获取到该桶里面的链表头结点，此时线程A的时间片用完了，而此时线程B被调度得以执行，和线程A一样执行，只不过线程B成功将记录插到了桶里面，假设线程A插入的记录计算出来的 hash桶索引和线程B要插入的记录计算出来的 hash桶索引是一样的，那么当线程B成功插入之后，线程A再次被调度运行时，它依然持有过期的链表头但是它对此一无所知，以至于它认为它应该这样做，如此一来就覆盖了线程B插入的记录，这样线程B插入的记录就凭空消失了，造成了数据不一致的行为。
- 2 resize而引起死循环
这种情况发生在HashMap自动扩容时，当2个线程同时检测到元素个数超过 数组大小 × 负载因子。此时2个线程会在put()方法中调用了resize()，两个线程同时修改一个链表结构会产生一个循环链表（JDK1.7中，会出现resize前后元素顺序倒置的情况）。接下来再想通过get()获取某一个元素，就会出现死循环。

### HashMap和HashTable的区别
- 1 HashMap几乎可以等价于Hashtable，除了HashMap是非synchronized的，并可以接受null(HashMap可以接受为null的键值(key)和值(value)，而Hashtable则不行)。
- 2 HashMap是非synchronized，而Hashtable是synchronized，这意味着Hashtable是线程安全的，多个线程可以共享一个Hashtable；而如果没有正确的同步的话，多个线程是不能共享HashMap的。Java 5提供了ConcurrentHashMap，它是HashTable的替代，比HashTable的扩展性更好。
- 3 另一个区别是HashMap的迭代器(Iterator)是fail-fast迭代器，而Hashtable的enumerator迭代器不是fail-fast的。所以当有其它线程改变了HashMap的结构（增加或者移除元素），将会抛出ConcurrentModificationException，但迭代器本身的remove()方法移除元素则不会抛出ConcurrentModificationException异常。但这并不是一个一定发生的行为，要看JVM。这条同样也是Enumeration和Iterator的区别。
- 4 由于Hashtable是线程安全的也是synchronized，所以在单线程环境下它比HashMap要慢。如果你不需要同步，只需要单一线程，那么使用HashMap性能要好过Hashtable。
- 5 HashMap不能保证随着时间的推移Map中的元素次序是不变的。

## SparseArray
SparseArray构造方法中，创建了两个数组mKeys、mValues分别存放int与Object，其默认长度为10。
本质上就是两个数组

来看代码
```
// 构造方法
public SparseArray() {
    this(10);
}

// 构造方法
public SparseArray(int initialCapacity) {
    if (initialCapacity == 0) {
        mKeys = EmptyArray.INT;
        mValues = EmptyArray.OBJECT;
    } else {
        // key value各自为一个数组，默认长度为10
        mValues = ArrayUtils.newUnpaddedObjectArray(initialCapacity);
        mKeys = new int[mValues.length];
    }
    mSize = 0;
}
```
总结：
- 1 SparseArray的key为int，value为Object
- 2 Android中，数据长度小于千时，用于替换HashMap,数据条数特别多的时候，效率会低于HashMap，因为它是基于二分查找去找数据的
- 3 占用内存空间小，没有额外的Entry对象







